{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a856b246-ff27-4cc0-90ad-806b88d51bd6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=6>\n",
    "\n",
    "<b>Curso de Análisis de Datos con Python</b>\n",
    "</font>\n",
    "\n",
    "<font size=4>\n",
    "    \n",
    "Curso de formación interna, CIEMAT. <br/>\n",
    "Madrid, Junio de 2023\n",
    "\n",
    "Antonio Delgado Peris (Cristina Labajo Villaverde)\n",
    "</font>\n",
    "\n",
    "https://github.com/andelpe/curso-python-analisis-datos\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293763e5-0dfb-4c1e-bb8b-379aa0b19446",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tema 7. Análisis exploratorio (EDA) y pre-procesado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff5d8b-9bbf-4b16-91a4-46a3e71cbcbd",
   "metadata": {},
   "source": [
    "Lo más importante a la hora de analizar datos y trabajar con datasets es disponer de unos buenos datos. No solo tienen que ser lo suficientemente representativos para satisfacer nuestros objetivos, si no que también requieren de un pre-procesado para limpiarlos, reescalarlos, agruparlos, convertir a un formato específico, etc. y así evitar errores en los resultados o resultados poco fidedignos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61dbd02-8cdc-4a74-aafb-a08544548354",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d51ff-6279-4aee-83ac-339232a692e4",
   "metadata": {},
   "source": [
    "- Identificar y limpiar los datos de valores _omitidos_\n",
    "- Estandarizar el formato de los datos\n",
    "- Normalizar los valores de los que disponemos\n",
    "- Agrupar valores (_binning_)\n",
    "- Variables categóricas y variables numéricas\n",
    "- Explorar los datos de los que disponemos \n",
    "- Encontrar relación entre las distintas variables\n",
    "- Identificación de _outliers_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb315c-9991-49fe-82f6-aff2415fdd92",
   "metadata": {},
   "source": [
    "## Importación de librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeeeb5e-3265-445f-8703-eb736c984b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd9d1b-0ad3-41f3-bd9e-fe3e2285b8b0",
   "metadata": {},
   "source": [
    "##  Estadística descriptiva\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1eb7f-5c44-46b8-bf5e-78f4795f3354",
   "metadata": {},
   "source": [
    "Es importante explorar nuestros datos antes de empezar a hacer cálculos complicados con ellos. \n",
    "Una vez que tenemos nuestros datos guardados en un dataset podemos aplicar distintos métodos para tener una primera idea del tamaño, rango y otras medidas estadísticas de interés, tales como el valor medio, máximos, mínimos, etc., que luego podemos necesitar para pre-procesar nuestros datos. \n",
    "\n",
    "La estadística descriptiva ayuda a describir las características básicas de un conjunto de datos de manera rápida.\n",
    "\n",
    "El modo más común de obtener estos datos es la función `df.describe()` de Pandas aplicada a nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9218b-07e2-432c-badb-0070230a0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EJEMPLO COCHES\n",
    "coches = pd.read_csv('data/auto-mpg.data',sep='\\s+', header=None)\n",
    "coches.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "                  'acceleration','model_year','origin','car_name']\n",
    "coches = coches.replace('?', np.nan).dropna().reset_index(drop=True)\n",
    "coches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0901c3-30b7-4e12-b519-009541bf35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de2c28-e9d8-4e68-83e7-c0aada38a7f9",
   "metadata": {},
   "source": [
    "Esta función muestra estadísticas básicas de cada variable, tales como la media, el total de datos, la desviación estandar, los cuartiles y el máximo y mínimo. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6cd284-83e4-4253-993c-69ca3d411054",
   "metadata": {},
   "source": [
    "También podemos usar la función `.info()` que nos dará otro tipo de información, como el rango del índice de nuestros datos (número de filas) y datos de nuestras columnas, como el tipo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb2992-5843-4ed3-8f1c-d17d95b82856",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EJEMPLO TRABAJADORES EMPRESA\n",
    "datos = [\n",
    "    {'Nombre': 'Juan', 'Sexo':'Hombre','Edad': 42, 'Departamento': 'Comunicación'},\n",
    "    {'Nombre': 'Laura', 'Sexo':'Mujer','Edad': 44, 'Departamento': 'Administración'},\n",
    "    {'Nombre': 'Pepe', 'Sexo':'Hombre','Edad': 37, 'Departamento': 'Ventas'},\n",
    "    {'Nombre': 'Carlos', 'Sexo':'Hombre','Edad': 15, 'Departamento': 'Ventas'},\n",
    "    {'Nombre': 'Esther', 'Sexo':'Mujer','Edad': 62, 'Departamento': 'Administración'},\n",
    "    {'Nombre': 'Álvaro', 'Sexo':'Hombre','Edad': 62, 'Departamento': 'Ventas'},\n",
    "    {'Nombre': 'Rosa', 'Sexo':'Mujer','Edad': 50, 'Departamento': 'Comunicación'},\n",
    "    \n",
    "]\n",
    "\n",
    "empresa = pd.DataFrame(datos)\n",
    "empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49a3b1-5cbb-40f4-839e-9728d631675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "empresa.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbdffc5-c9fb-4627-b2ac-184a4f6ede04",
   "metadata": {},
   "source": [
    "Aunque para saber las dimensiones de nuestro dataset la manera más rápida es usar la función `.shape` que nos devuelve dos números, el primero es el número de filas y el segundo el número de columnas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e76553-5869-417d-8b44-fc41aba39577",
   "metadata": {},
   "outputs": [],
   "source": [
    "empresa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d75dfa-d5b7-4e3f-8423-38d4f81d4830",
   "metadata": {},
   "source": [
    "Dos funciones útiles para conocer los valores que tenemos en nuestras columnas son `value_counts`, y `unique`, especialmente para el caso de variables categóricas.\n",
    "\n",
    "La función `df.columna.unique()` nos indica los valores únicos presentes. La función `df.columna.value_counts()` nos dice cuántas veces se repite cada valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b441d82-a8a9-4a3d-b3ac-3c49dc2fbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "empresa.Departamento.unique()  # O: pd.unique(empresa.Departamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837d752-0b47-4fec-b839-22c1004a5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "empresa.Departamento.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376dfe7b-8c52-40d7-aec8-911fafd524ef",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "### Histogramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22b6f5-b3ac-4ee4-89f3-fc1f48df459f",
   "metadata": {},
   "source": [
    "Una forma gráfica de ver la distribución de nuestros datos es crear un **histograma**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4bcca-86cf-44c1-b2eb-0370731fadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EJEMPLO Coches CO2 emissions\n",
    "df4 = pd.read_csv(\"data/FuelConsumption.csv\")\n",
    "coches2 = df4[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB','CO2EMISSIONS']] \n",
    "coches2 ## Datasat reducido con variables de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9b158-08eb-4f54-87d1-5084cffa06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "sns.histplot(\n",
    "        data    = coches2,\n",
    "        x       = 'ENGINESIZE',\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = 'green',\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,  # transparency\n",
    "        ax      = axes[0])\n",
    "axes[0].set_title('Engine Size', fontsize = 10, fontweight = \"bold\")\n",
    "axes[0].tick_params(labelsize = 8)\n",
    "\n",
    "\n",
    "sns.histplot(\n",
    "        data    = coches2,\n",
    "        x       = 'CO2EMISSIONS',\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = 'orange',\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3, \n",
    "        ax      = axes[1])\n",
    "axes[1].set_title('Emisiones CO2', fontsize = 10, fontweight = \"bold\")\n",
    "axes[1].tick_params(labelsize = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293cd774-5cae-458c-b8d7-5c81efa1b7b7",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377f0d1-5296-40ab-90ad-15129f48784b",
   "metadata": {},
   "source": [
    "El diagrama de cajas o *boxplot* es un método estandarizado para representar gráficamente una serie de datos numéricos a través de sus cuartiles. De esta manera, se muestran a simple vista la mediana y los cuartiles de los datos y también pueden representarse sus valores atípicos.\n",
    "También proporcionan una visión general de la simetría de la distribución de los datos; si la mediana no está en el centro del rectángulo, la distribución no es simétrica.\n",
    "\n",
    "Usaremos la librería seaborn para construir los diagramas de cajas, más concretamente la función [`.boxplot()`](https://seaborn.pydata.org/generated/seaborn.boxplot.html)\n",
    "\n",
    "Si lo que queremos es agrupar los datos dependiendo de otra variable, la definiremos en el eje x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6f206-64c3-4c00-bbc7-0d2764b77f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot vertical\n",
    "figure,axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "sns.boxplot(y=empresa.Edad, data=empresa, ax=axes[0])\n",
    "axes[0].set_title('Edad',fontsize = 10)\n",
    "\n",
    "sns.boxplot(x=empresa.Sexo, y=empresa.Edad, data=empresa, ax=axes[1])\n",
    "axes[1].set_title('Edad en función del Sexo',fontsize = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5af4d3-293d-40c8-8493-ca612865faeb",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "<div style=\"background-color:powderblue;\">\n",
    "\n",
    "**EJERCICIO e7_1:** \n",
    "\n",
    "Dado el dataset `ejer_titanic` visualizar usando un boxplot la edad de mujeres y hombres que había en el titanic, clasificados por la clase en la que viajaban.\n",
    "    \n",
    "- Pista: usar el argumento `hue` con la función `boxplot` de `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ae1e2-8665-4d24-9ff2-cddd7cbf6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EJEMPLO Dataset Titanic\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87bba2-83e0-4572-a3ce-f9465d177454",
   "metadata": {},
   "source": [
    "##  Valores ausentes\n",
    "Podemos encontrarnos con que faltan valores en nuestros datasets, esto puede deberse a que no se han guardado algunas variables de un evento, y podemos encontrarlos representados de diferentes maneras (p. ej. 0, NaN, espacios en blanco, o símbolos de puntuación).\n",
    "\n",
    "Primero, es necesario detectar si tenemos valores nulos u omitidos en nuestro dataset y eso lo podemos hacer usando la función de pandas `.isnull()`. También podemos combinarla con el método `.any` que nos dirá si hay algún nulo o ninguno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed07f8-77b8-4c6c-a34d-41065bce6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EJEMPLO Dataset Titanic\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f29a3a-3dde-4882-aac3-0de793117c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cac1e-02d3-4cd2-80b6-5c10bc4c6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head().isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ab723-c947-477a-be26-155d122cb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay algún nulo en mis columnas? \n",
    "titanic.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96335db0-dbac-48f1-8248-9bbad25bdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay algún nulo en todo el DataFrame? \n",
    "titanic.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124cf1d-5ddc-4450-99ab-12495b5f1b49",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "También podemos contar el número exacto de datos nulos por columna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f204e25-8dff-41b8-89fc-fa8dbac755c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652133f-f2b6-40fd-887b-6348b22b1671",
   "metadata": {},
   "source": [
    "\n",
    "Se pueden considerar diferentes estrategias para enfrentarnos a estos valores omitidos y eso va a depender de la situación, el tipo de dato y la experiencia del investigador. Los distintos métodos para solucionar los espacios en blanco son los siguientes: \n",
    "\n",
    "- Revisar los datos e intentar recuperar el valor desconocido. \n",
    "- Eliminar los datos omitidos\n",
    "    - Eliminar la variable entera \n",
    "    - Eliminar esa entrada de datos (la fila)\n",
    "- Sustituir valores\n",
    "    - Variables numéricas:\n",
    "        - Reemplazarlos por la media de la variable \n",
    "    - Variables categóricas:\n",
    "        - Reemplazarlos por la moda   \n",
    "        - Reemplazar los valores basándonos en conocimiento previo\n",
    "- Dejar en blanco los valores que faltan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da0112-7e41-474a-a5be-a4d5bb4baf25",
   "metadata": {},
   "source": [
    "### Eliminar los datos omitidos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a281ca-5c29-4361-9582-a6641c00c377",
   "metadata": {},
   "source": [
    "Pandas tiene una función que se encarga de eliminar datos que no son válidos o en blanco: `df.dropna()`\n",
    "\n",
    "Es necesario especificar el eje que queremos eliminar:\n",
    "- `axis=0` elimina la fila entera, la entrada que presenta problemas\n",
    "- `axis=1` elimina la columna, la variable\n",
    "\n",
    "Otros de los parámetros de la función que hay que configurar son la columna en la que se encuentra el NaN y si queremos mantener el índice cuando eliminemos los datos vacíos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a823ed8-d948-4393-aa5b-1176e0044a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_titanic = titanic.copy()\n",
    "\n",
    "# Borramos las filas (axis=0) que tengan NaN en la columna 'deck' (subset)\n",
    "del_titanic.dropna(subset=['deck'], axis=0, inplace=True)\n",
    "del_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec9911-ef81-4545-b951-1137b89ac83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982d209-31bd-4bc4-ae4f-2b4f35b4fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_titanic.deck.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fd7e0-6a59-4675-8eb0-296dc23f19af",
   "metadata": {},
   "source": [
    "Hemos borrado las filas con NaN en la columna 'deck', pero sigue habiendo Nan en otras columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f17c1-984f-4e59-8967-ff621d1b231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de1cfc-cba2-4f6c-8dbf-3e81e8b2fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora orramos en todo el Dataframe\n",
    "del_titanic_2 = titanic.dropna(axis=0)\n",
    "del_titanic_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29d993-752d-4557-922f-b96115409229",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_titanic_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fb057-71f0-4b2f-905c-fadc743851c4",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Al eliminar filas, nuestro índice tiene ahora valores no consecutivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df99c06-8c2f-4e50-ada0-29a356f2315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e25626-84b5-41be-b6b1-16960fb9f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos reiniciar el índice para que tenga valores consecutivos\n",
    "del_titanic.reset_index(drop=True, inplace=True)\n",
    "del_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4361e-c96f-4886-9353-83a5c4a99663",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sustituir valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d8d52-c13c-40f6-ba51-e7970664db53",
   "metadata": {},
   "source": [
    "Para sustituir un dato vacío por otro valor se puede usar la función `df.replace(valor_omitido, nuevo_valor)`.\n",
    "\n",
    "También existe una función especifica para los valores omitidos:`df.fillna(nuevo_valor)`\n",
    "\n",
    "Pongamos que el ejemplo del dataset anterior queremos reemplazar el valor NaN por el valor de la columna `deck` que más veces se repite, o lo que es lo mismo, la _moda_.\n",
    "\n",
    "Primero habría que calcular la moda con `df.col.mode()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c36bb1-3a7d-4478-9e21-00310d3eef28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Hallamos la moda\n",
    "md = titanic.deck.mode()[0]\n",
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2998a2f-2b8d-455a-88ca-355afb2466bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Sustituimos valores NaN por la moda hallada\n",
    "md_titanic = titanic.copy()\n",
    "md_titanic.deck = md_titanic['deck'].fillna(md)\n",
    "md_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79e654-0ad5-437a-8aff-b3553dd65ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que los NaN han desaparecido\n",
    "md_titanic.deck.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275bf8c-46fd-409a-92a2-8c0dcbd75cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora hay muchas 'C'\n",
    "md_titanic.deck[md_titanic.deck=='C'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca2549-a6c5-4cc8-b85b-3a7beb351e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pero todavía tenemos NaN en algunas otras columnas\n",
    "md_titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08aa7d8-37ab-4b9b-8ddb-62345b343215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el caso de la columna 'age', vamos a aplicar la función 'replace', para cambiarlos por 0s\n",
    "# La situación inicial es que hay varios NaN, pero ningún valor 0\n",
    "print('Num. filas con age==NaN -->', md_titanic.age.isnull().sum())\n",
    "print('Num. filas con age==0 -->', md_titanic.age[md_titanic.age == 0].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2ff62-478b-4356-a962-0fdda1e365be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el cambio\n",
    "md_titanic.age = md_titanic.age.replace(np.nan, 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1eb520-4cc3-4579-be4b-ad8b40d0374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y vemos sus efectos\n",
    "print('Num. filas con age==NaN -->', md_titanic.age.isnull().sum())\n",
    "print('Num. filas con age==0 -->', md_titanic[md_titanic.age == 0].age.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d41a586-27e4-4561-b0aa-c9741a81f351",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "<div style=\"background-color:powderblue;\">\n",
    "\n",
    "**EJERCICIO e7_2:** \n",
    "\n",
    "Dado el dataset `ejer2` remplaza los NaN de cada columna por la media de su correspondiente columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd252c3-e3c2-4b73-a3b6-31943f590fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ejer2 = pd.DataFrame({'a':[None, 3, None, 5, 6], 'b':[1, 3, 4, 6, None], 'c':[54, None, None, 32, 21]})\n",
    "ejer2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2488aac-edcf-46cb-ab50-779b07cba398",
   "metadata": {},
   "source": [
    "## Formateo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c51b2-a24d-429f-b8c4-8699e36c1d35",
   "metadata": {},
   "source": [
    "Puede darse el caso de que recolectemos datos de distintas fuentes, o que los registren diferentes personas por lo que los datos pueden presentar distintas nomenclaturas o no ser constantes en términos de unidades y formatos. En este caso resulta difícil comparar los datos o agruparlos por lo que es necesario formatearlos y definir un formato único que haga más fácil las futuras operaciones. \n",
    "\n",
    "En el caso en que se requiera una conversión de unidades, por ejemplo pasar los datos de peso de libras a kg, debemos dividir las libras entre 0,45359237. Podemos modificar la columna `libras` de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219d175-2172-4124-a230-6d7b0474031d",
   "metadata": {},
   "source": [
    "`df['libras'] = df['libras']/0.45359237`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07202822-15eb-4eef-b082-9b471213cbcf",
   "metadata": {},
   "source": [
    "Conviene en este caso renombrar la columna:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05796ec7-ed05-4265-9057-dd901af3ee43",
   "metadata": {},
   "source": [
    "`df.rename(columns={'libras':'kilogramos'}, inplace=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05cdd96-ab64-4f10-86a7-174e64162d23",
   "metadata": {},
   "source": [
    "Es importante prestar atención al tipo de datos que tenemos. Si no son los correctos puede haber errores en las operaciones cuando construyamos modelos. \n",
    "\n",
    "Cuando introducimos datos en python puede ocurrir que se registren como un tipo distinto al que deseamos. Es necesario comprobar el tipo de datos y ver si se corresponden con lo que debería ser para que no interfiera en nuestros futuros cálculos, si este no fuera el caso, se debe de cambiar el tipo de datos. \n",
    "\n",
    "Para identificar qué tipos de datos tenemos usamos la función `dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd07d5-6da0-408d-be9b-e2e0e1d5883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b473366-d8c8-46d0-860e-02a5b09740a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d41a58-afc9-4512-ba49-46d5102e1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches.horsepower[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e72dc7-a634-4f2c-a6dc-cb8f80856810",
   "metadata": {},
   "source": [
    "Para cambiar el tipo de una columna se puede usar la función `astype` especificando el tipo al que vamos a convertir la variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8716e-3dca-4359-80ab-72062f00c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos todas las columnas numéricas a float\n",
    "coches.iloc[:,:-1] = coches.iloc[:,:-1].astype(float)\n",
    "coches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ca2e3-c823-4225-8dca-0a1c1adde800",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches.horsepower[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863515f-6b30-46f7-b6f3-690428d4f099",
   "metadata": {},
   "source": [
    "NOTA: Un caso particular a tener en cuenta es si una columna con valores numéricos tiene tipo `object`. Eso suele provenir de un error de importación de los datos, que se han considerado _string_, y dará problemas en futuras operaciones matemáticas. Se debe corregir con `astype`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2feede2-b907-4450-95a0-026ae5d4fc0a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:powderblue;\">\n",
    "\n",
    "**EJERCICIO e7_3:** \n",
    "\n",
    "Convertir la columna `mpg` (_miles per gallon_) del dataframe `ejer_coches` a litros cada 100km.\n",
    "    \n",
    "La fórmula a sefuir es la siguiente $L/100km = 235 / m.p.g.$\n",
    "\n",
    "Cambiar el nombre de la columna a `L/100km`\n",
    "\n",
    "Comprobar el tipo de la columna modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c91df4-19b0-4882-a354-6e6f0b5dfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejer_coches = coches.copy()\n",
    "ejer_coches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af1cd1-0695-448e-a6d6-3c3d6aa3503e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b65ed9-9cf5-40a8-9520-d6cf4a97f524",
   "metadata": {},
   "source": [
    "Muchas veces, dependiendo de la naturaleza de los datos, nos encontramos con que hay gran variación de rango entre una columna y otra. Por ejemplo en el siguiente dataframe de casas, entre el precio y el número de habitaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e5e7d-679b-47bc-a951-bff38df1ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EJEMPLO CASAS\n",
    "casas = pd.read_csv('data/kc_house_data.csv', header='infer')\n",
    "casas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89d398-84df-471b-959f-4b048ff73cc6",
   "metadata": {},
   "source": [
    "\n",
    "En estos casos puede venir bien normalizar nuestros datos. Normalizar significa, en este caso, comprimir o extender los valores de la variable para que estén en un rango definido y hacer que los datos sean más uniformes, para facilitar futuros cálculos estadísticos con nuestro dataset. \n",
    "\n",
    "La normalización hace posible la comparación entre distintas variables (_features_) y hace que todas tengan el mismo impacto en los cálculos.\n",
    "\n",
    "Pero no existe un método ideal de normalización que funcione para todas las formas de variables. Es trabajo del científico conocer cómo se distribuyen los datos, saber si existen anomalías, comprobar rangos, etc.\n",
    "\n",
    "Hay varios métodos para normalizar, pero a continuación explicaremos tres y veremos cómo se implementan en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01464b3d-1a36-4149-9ac6-8af248070b1e",
   "metadata": {},
   "source": [
    "### Escalado de variables (Feature Scaling):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017f602-c1ec-4b8d-b921-5d86436dd965",
   "metadata": {},
   "source": [
    "#### Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b15dda-cfa1-4e15-a960-791fcee74c65",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "$$x_{new} = \\frac{x_{old}}{x_{max}}$$\n",
    "\n",
    "Se divide cada valor por el máximo valor de esa variable. El nuevo rango de la variable es entre [0,1].\n",
    "\n",
    "Esto aplicado a nuestro dataset sería de la siguiente forma:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90424cf8-6a4f-4cc3-a450-ae93d2e92add",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = casas['price']\n",
    "var.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d172a8-867b-4497-a724-65dc713821f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_norm_max = var / var.max()\n",
    "price_norm_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294b922-4a85-472f-8efc-04e41bcea7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_norm_max.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ebfa5-8a14-40e4-a876-3420fad64d06",
   "metadata": {},
   "source": [
    "#### Min-Max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0b91a-57fa-4595-ac86-6fb72f7eaf22",
   "metadata": {},
   "source": [
    "\n",
    "$$x_{new} = \\frac{x_{old} - x_{min}}{x_{max}- x_{min}}$$\n",
    "\n",
    "El nuevo valor es el resultado de dividir la diferencia entre el valor original menos el valor mínimo, por el rango de dicha variable (máximo - mínimo). El nuevo rango de la variable será también [0,1].\n",
    "\n",
    "Siguiendo el ejemplo anterior pero aplicando la normalización Min-Max:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25c4cc-38a5-489d-80ea-d5e3b0d9893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_norm_minmax = (var - var.min()) / (var.max() - var.min())\n",
    "price_norm_minmax.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955e08a-be62-440a-a001-9f52cfcfdf63",
   "metadata": {},
   "source": [
    "### Escalado estándar (Z-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b2cac-2d0f-44bf-b0c2-1bf9868ed3c4",
   "metadata": {},
   "source": [
    "Otra forma de normalización es la llamada _Z-score_, que es una medida de cuántas desviaciones estándar por debajo o por encima de la media se encuentra un valor concreto.\n",
    "\n",
    "Se calcula restando la media y dividiendo por la deviación estándar.\n",
    "\n",
    "$$x_{new} = \\frac{x_{old} - \\mu }{\\sigma}$$\n",
    "\n",
    "Un valor Z de cero indica que los valores son exactamente la media, mientras que un valor de +3 indica que el valor es mucho más alto que la media.\n",
    "\n",
    "En una distribución gaussiana nos indica también en qué percentil de la distrubución nos encontramos. En ese casi todos los valores normalizados quedarán dentro del rango [-3, 3].\n",
    "\n",
    "<center>\n",
    "<img src=\"images/t7_zscore.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3dbafd-08e0-41f2-bd48-1a76e79ef3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = coches2['CO2EMISSIONS']\n",
    "co2_norm_zscore = (var - var.mean()) / var.std()\n",
    "co2_norm_zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b4f803-6dd4-4efe-a038-f01e991c9c00",
   "metadata": {},
   "source": [
    "También la librería Scipy nos ofrece una fórmula que nos lo calcula directamente: `stats.zscore()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057399d-ca66-46b0-b63c-aebc89378392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ZS = stats.zscore(var, ddof=1)\n",
    "print(ZS[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8ac7d-f939-4967-811f-8f6fc6ff0d0c",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "<div style=\"background-color:powderblue;\">\n",
    "\n",
    "**EJERCICIO e7_4:** \n",
    "\n",
    "Normaliza el dataset ejer_coches2 utilizando la función Min-Max. Cada columna debe ir normalizada usando el máximo y mínimo correspondiente. \n",
    "\n",
    "Comprobar que los valores resultantes están en el rango [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220578f-be29-40e9-8f23-dd7a94b8597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejer_coches2 = coches2.copy()\n",
    "ejer_coches2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eee45b-1d1d-4f55-bc29-580eb9026190",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discretización (Binning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc18ef-4f5c-4961-bf25-c514545cb065",
   "metadata": {},
   "source": [
    "_Binning_ es la división de los datos en grupos (_bins_), en base un criterio dado (p. ej., rangos de valores en alguna de las variables).\n",
    "\n",
    "Al crear un histograma, por ejemplo, se hace un binado implícito. la altura de cada barra mostrada se hace de acuerdo al número de registros que _caen_ dentro de cada _bin_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec51d9-ae3c-4892-8ad3-66aae0a1552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "coches2['CO2EMISSIONS'].plot(kind='hist',edgecolor='black', bins=10, title='CO2EMISSIONS');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1afa45b-db33-4caf-b7fb-486887152c7b",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "Existen dos funciones en pandas que se usan para dividir nuestros datos en bins: `cut` y `qcut`.\n",
    "\n",
    "Veamos primero `cut`:\n",
    "\n",
    "- [`cut`](https://pandas.pydata.org/docs/reference/api/pandas.cut.html): Divide las muestras en intervalos indicados explícitamente, o para un número total de _bins_ del mismo tamaño. La función sobre una serie de valores devuelve el intervalo que corresponde a cada posición del índice original.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd023f5-df5e-4cc6-8c11-5ca7145a97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores\n",
    "coches2['CO2EMISSIONS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108e3b5-a48f-4398-8040-7205db3317b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be940a6-758a-4864-871c-29c35d9156f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin para cada valor\n",
    "pd.cut(coches2['CO2EMISSIONS'], bins=4).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b65d3-dcd1-4f34-a37d-3fd08f717533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con 'value_counts' podemos obtener las frecuencias por bin (histograma)\n",
    "pd.cut(coches2['CO2EMISSIONS'], bins=4).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479e8bc-cdd9-4a73-88fc-da2dfad08237",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches2['CO2EMISSIONS'].plot.hist(bins=4,edgecolor='black');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184ee8b-d7ec-4b9c-b141-f9f2b1d34972",
   "metadata": {},
   "source": [
    "Con el argumento 'retbins' obtenemos los valores utilizados para dividir los intervalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ca98b-8298-47ff-8c16-c10b306ee82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, bins = pd.cut(coches2['CO2EMISSIONS'], bins=4, retbins=True)\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c65a1-0f8f-42f2-8487-8c5538dbaa0b",
   "metadata": {},
   "source": [
    "Podemos comprobar que los intervalos tienen todos la misma longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6585e3-6fba-409e-928d-49cdb2b8bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins[1:]-bins[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d00a55-1ac7-4453-80b9-1c8ebd6afb36",
   "metadata": {},
   "source": [
    "Veamos finalmente un ejemplo de `cut` con bins especificados explícitamente (y tamaños irregulares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc90083-c971-44fa-8087-11a9250b6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.IntervalIndex.from_tuples([(0.0, 90.0), (91.0,251.0), (252.0, 488.0)])\n",
    "\n",
    "pd.cut(coches2['CO2EMISSIONS'], bins).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d296e5-a9d7-4963-9f98-9891ffd573fe",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "Veamos ahora `qcut`:\n",
    "\n",
    "- [`qcut`](https://pandas.pydata.org/docs/reference/api/pandas.qcut.html)\n",
    "La documentación de pandas describe `qcut` como una \"función de discretización basada en cuantiles\". `qcut` calculará el tamaño de cada bin para asegurarse de que la distribución en los bins es la misma (más o menos) en todos ellos. En general, los bins no serán de igual tamaño, el rango variará, pero todos tendrán el mismo número de observaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c59bf0-19f2-46f4-abb8-afd4d8c2b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, bins = pd.qcut(coches2['CO2EMISSIONS'], q=5, retbins=True)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c64613-69ad-487a-b204-51a3d28fe8a3",
   "metadata": {},
   "source": [
    "Ahora tendremos intervalos irregulares, pero poblaciones por bines aproximadamente iguales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1218a536-ad57-4350-b1e3-73a5e40a378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins[1:]-bins[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcebf838-5dc1-43dd-8633-0508cc592509",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d6f0b-a598-4646-9ca7-989a8767f93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02304fdc-fcaf-48a2-9678-b8c8e68baeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora especificamos los cuantiles, en lugar del número de ellos\n",
    "h2, bins = pd.qcut(coches2['CO2EMISSIONS'], q=[0, 0.25, 0.5, 0.75, 1], retbins=True)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26552f-0df4-4cbd-9fb9-c8481ba5a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e63a14-09d3-4d6c-8c4b-417663571230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos con lo que nos muestra 'describe'\n",
    "coches2['CO2EMISSIONS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f598c6-fc7d-4a32-a00e-77c35cdc9863",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "Además de para conocer mejor la distribución de nuestros datos, otra aplicación posible del binado es la de poner etiquetas a los distintos grupos y convertir variables numéricas en variables categóricas. \n",
    "\n",
    "Por ejemplo, usando `cut` podemos clasificar los coches del ejemplo anterior en función de su nivel de emisión de CO2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18b64c-c8f6-4944-8a81-deb68e6da82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_emissions = ['Muy poco', 'Poco', 'Normal', 'Mucho']\n",
    "clasif = pd.cut(coches2['CO2EMISSIONS'], bins=4, labels=labels_emissions)\n",
    "clasif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0f167-6606-4244-981d-60b3368d110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coches2['Contamina'] = clasif\n",
    "coches2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037bc015-dd7d-498c-bc25-1e97192b68ec",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "<div style=\"background-color:powderblue;\">\n",
    "    \n",
    "**EJERCICIO e7_5:** \n",
    "\n",
    "Clasifica a los trabajadores de una empresa en grupos de edad (categóricos) usando la función cut. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8fc76f-c968-4102-9100-bbd9a813f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejer_edad = empresa.copy()\n",
    "ejer_edad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e843e9-fba1-469b-8f2f-b6b80b8af456",
   "metadata": {},
   "source": [
    "## Variables categóricas y variables numéricas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6d3b0-6f00-45dc-a854-808959c98a64",
   "metadata": {},
   "source": [
    "Para poder hacer operaciones sobre nuestros datos o construir modelos (clases de Python que representan funciones matemáticas, p. ej. una regresión lineal) normalmente requerimos variables numéricas. Por lo tanto, cuando tenemos variables categóricas tenemos que realizar una conversión previa.\n",
    "\n",
    "Existen diferentes métodos para hacer esta conversión de categórico a numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b348ba-9476-4d45-8cd3-d0a11655c7b2",
   "metadata": {},
   "source": [
    "### Convención"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe54785-4795-4c2e-be5f-4bf173821086",
   "metadata": {},
   "source": [
    "Se puede establecer un código para poner etiquetas a las distintas categorias que tengamos de forma manual, por ejemplo, si quisieramos cambiar la variable `Sexo` del siguiente dataset a numérico, podríamos acordar que `Mujer` se representa por `1` y `Hombre` por `2`.\n",
    "\n",
    "\n",
    "Nombre | Sexo | Sexo_num\n",
    ":--------: | ------- | --------\n",
    "Juan | Hombre | 2\n",
    "Laura| Mujer | 1\n",
    "Pepe| Hombre | 2\n",
    "Carlos| Hombre | 2 \n",
    "Esther | Mujer | 1 \n",
    "Álvaro | Hombre | 2 \n",
    "Rosa | Mujer | 1 \n",
    "\n",
    "\n",
    "De este modo tendríamos la variable convertida a numérico. El código para conseguirlo sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35d5ac-56a2-4cb8-9fb3-f5744b36c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "empresa[\"Sexo_num\"] = empresa.apply(lambda x: 1 if x[\"Sexo\"] == 'Mujer' else 2, axis=1)\n",
    "empresa[['Nombre','Sexo','Sexo_num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361886b-5d22-43da-ac95-5a0ec22acdef",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a2d9a-492d-420a-9306-8ab754ceba1c",
   "metadata": {},
   "source": [
    "Este método consiste en crear unas variables extras con el nombre de cada etiqueta e indicar con 1s y 0s la categoría a la que pertenece cada evento (1=si, 0=no).\n",
    "Por ejemplo, fijémosnos en la clase en la que viajaban los pasajeros del Titanic. Una variable categórica que puede ser Primera, Segunda o Tercera (First, Second, Third):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a18288-1d8e-4de8-be35-375efaf66558",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['class'].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b438dc-9532-4877-9654-205a220ec74e",
   "metadata": {},
   "source": [
    "Al hacer One Hot Encoding crearemos tres nuevas variables, cada una con el nombre de uno de los valores de `titanic['class']`, y estas clases son excluyentes, por lo que hay que tener en cuenta, que no importa el número de categorías o etiquetas que tengamos, sólo una de ellas puede ser 1 siendo el resto 0. \n",
    "\n",
    "Para poder crear estas variables ficticias o \"dummy variables\" se usa la función de pandas [`.get_dummies`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f1787-2795-4040-91c8-27bef2db53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE = pd.get_dummies(titanic['class'])\n",
    "OHE.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2529c-a612-4ec4-85e3-c7206990cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([titanic[['class']], OHE], axis=1).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143a282-49fb-4786-b141-1ad198d7ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([titanic, OHE], axis=1).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56293dce-1180-44e9-b749-2dda4c4fc139",
   "metadata": {},
   "source": [
    "<p/>\n",
    "\n",
    "<div style=\"background-color:powderblue;\">\n",
    "\n",
    "**EJERCICIO e7_6:**\n",
    "\n",
    "Dado el dataset `ejer_empresa` convierte a numérico los departamentos a los que pertenecen los trabajadores usando One-Hot-Encoding. \n",
    "\n",
    "Utiliza esta codificación para calcular el número de trabajadores que trabajan en cada departamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d2218-ad37-4968-a7bc-24e56ee9a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejer_empresa = empresa.copy()\n",
    "ejer_empresa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4176c-8f35-49cb-9752-01f244bab643",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40b0ab-7660-4c5f-97e6-023630b74455",
   "metadata": {},
   "source": [
    "La correlacción es un método usado en estadística para saber hasta que punto dos variables son independientes entre sí, cómo afecta el cambio de una de estas variables a la otra.\n",
    "\n",
    "Esta relación no tiene por qué ser de causalidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db293b48-93bc-4f39-a6c1-10a1d331a6af",
   "metadata": {},
   "source": [
    "Vamos a ver el ejemplo práctico de correlación entre el precio de una casa y la superficie habitable de esta. Podemos visualizarlo con la función `sns.regplot`, que produce un gráfico de dispersión y muestra además la recta de regresión lineal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69785a43-8486-4884-894c-d74b4cafc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='sqft_living', y='price', data=casas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c727c9d-e846-453d-8817-4269e5db5fae",
   "metadata": {},
   "source": [
    "En este ejemplo, vemos que la recta tiene una pendiente positiva, que nos indica que el valor medio de los edificios tiene relación con el número total de superficie habitable. Una pendiente negativa indicaría una correlación inversa y una pendiente cercana a cero (línea horizontal) nos indicaría que no hay correlación entre esas dos variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fa51b-17fe-4cac-a053-96aba992dbd6",
   "metadata": {},
   "source": [
    "### Coeficiente de Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad9e52-cc76-4598-be4f-3ca100c0631a",
   "metadata": {},
   "source": [
    "La correlación de Pearson es la medida de cuán fuerte es una correlación. Nos da dos valores: El coeficiente de correlación y el P-value\n",
    "\n",
    "- **Coeficiente de Correlación**: Nos muestra el grado de correlación entre dos variables. El rango de este coeficiente es [-1,1]. Si el valor se acerca a -1 nos indica que hay una fuerte correlación y que esta es negativa, si el valor es cercano a 1 es una correlación fuerte y positiva y si es 0 significa que no hay correlación.  \n",
    "\n",
    "- **P-value**: Mide la probabilidad de obtener los resultados asumiendo que cierta hipótesis (nula) es cierta. Cuanto más bajo sea el p-value, mayor es el significado estadístico de la diferencia observada. En este caso, nos da la probabilidad de que dos distribuciones aleatorias produjeran en coeficiente de correlación obtenido.\n",
    "\n",
    "Una correlación fuerte tiene que cumplir ambos criterios, un coeficiente cercano a 1 o -1 y un p-value lo más bajo posible.\n",
    "\n",
    "Vamos a usar la función [`.pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)de la librería Scipy que contiene herramientas y algoritmos matemáticos y vamos a ver lo fuerte o débil que es la correlación entre el número de habitaciones y el precio de los edificios del ejemplo anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab15ad-3909-4550-9c7b-8d16dd997095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "pearson_coef, p_value = stats.pearsonr(casas.price, casas.sqft_living)\n",
    "print('Coeficiente de Pearson:', pearson_coef)\n",
    "print('P-value:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dded3c-341a-4fd9-b20d-0549b0505b3b",
   "metadata": {},
   "source": [
    "NOTA: obtener un valor de 0 para el p-value, significa que es muy muy bajo (pero no será 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f571d8c-da29-4d27-bd81-615c3a367afa",
   "metadata": {},
   "source": [
    "### Matriz de correlación\n",
    "Para correlacionar más de dos variables, podemos utilizar una matriz de correlación, que muestra la correlación entre todas las variables, dos a dos.\n",
    "\n",
    "Para crear la matriz de correlación de un Dataframe entero, podemos usar la función `.corr` de Pandas que, por defecto, calcula el coeficiente de correlación de Pearson pero también podemos especificar la utilización de otros métodos de correlación pasando un valor apropiado al parámetro `method`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcc145-ecbb-4d5a-bb14-2eb575ce8fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = casas.iloc[:,2:9]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d17acf2-73bd-4608-8c4d-1979bf7f2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mat = sub.corr()\n",
    "correlation_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8030df-405a-495d-ab62-bc3013374cd1",
   "metadata": {},
   "source": [
    "Una forma visual de representar la matriz de correlación es usar un mapa de calor, en los que cada color representa un valor del coeficiente. Podemos crearlos usando la función `heatmap()` de Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b7af3-2f97-48df-a095-d4f1a6057733",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.title('Correlation matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b1038-e7a2-44b8-83cd-452e49716c79",
   "metadata": {},
   "source": [
    "Si nos fijamos, la diagonal de la matriz es todo 1s, que es la correlación de cada variable consigo misma. Obviamente, esta es máxima.\n",
    "\n",
    "Y si buscamos el cruce entre `sqft_living` y `price`, encontramos el valor de 0.7 obtenido antes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7601852-5e49-44a6-b392-7134eed8541b",
   "metadata": {},
   "source": [
    "## Valores atípicos (outliers)\n",
    "Un valor atípico o *outlier* es una observación que difiere de los datos que de otro modo estarían bien estructurados. Es un valor que numéricamente es muy distinto al resto de los datos, lo que puede afectar a nuestros datos. Por ejemplo, si tenemos datos de emisiones de CO2 de coches y uno de ellos resulta que tenía un problema de fábrica y emitía más. \n",
    "Ese dato nos va a afectar a la media y a los cuartiles, y puede ser que queramos identificar ese dato para poder eliminarlo de nuestro dataset.\n",
    "\n",
    "Es imprescindible conocer la naturaleza de nuestros datos para saber si tiene sentido eliminar outliers, y no supone pérdida importante de información.\n",
    "\n",
    "A menudo, podemos identificar outliers a simple vista en un histograma, pero en los boxplots estos se muestran explícitamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730c0f6-25b5-4c49-ac79-a300f4353eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "casas.price.plot(kind='hist',edgecolor='black', bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877acb2-d957-43fb-92f8-9649284dac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,12))\n",
    "plt.boxplot(casas.price, vert=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bcdc89-2009-4e3a-b442-c836a85fa959",
   "metadata": {},
   "source": [
    "Una manera programática de detectarlos es usar los Z-score que hemos visto con anterioridad. Si se alejan más de 3 deviaciones estándar de la media pueden considerarse outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3de387-64ba-4e26-ba46-3513681edc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero calculamos los Z-scores de la columna que nos interesa analizar.\n",
    "ZS = stats.zscore(casas.price)\n",
    "\n",
    "# Y nos quedamos con el valor absoluto\n",
    "casas['abs_z_scores'] = np.abs(ZS)\n",
    "precios = casas[['price', 'abs_z_scores']]\n",
    "precios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef7f82-a2e4-4c36-8740-c38683938ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precios[precios['price']>1000000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efa095-c26c-4ee2-bfa7-18466720852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las filas con un |Z-score| menor de 3\n",
    "print('Num. registros total:', precios.shape[0])\n",
    "\n",
    "new_precios = precios[precios['abs_z_scores'] < 3] \n",
    "print('Num. registros sin outliers:', new_precios.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a5803-0ea1-4eaa-9e7f-8031336738d1",
   "metadata": {},
   "source": [
    "O, recíprocamente, podemos quedarnos con los valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd23356-89e8-486e-a323-bcfa44b1b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos solo aquellos que tienen un Z-score mayor o igual de 3\n",
    "outliers_precios = precios[precios['abs_z_scores'] >= 3]\n",
    "print('Num. outliers:', outliers_precios.shape[0])\n",
    "outliers_precios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ff902-ab8e-4a06-8136-b99c67546ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precio medio de todas las casas: {precios['price'].mean():.0f}\")\n",
    "print(f\"Precio medio de los outliers:   {outliers_precios['price'].mean():.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
